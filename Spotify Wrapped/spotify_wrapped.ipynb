{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "C_Z4WDkT59F-",
        "KO-0JCDxPNP6",
        "GCJstxwgPRKm",
        "z3IREe9LkYVA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stream Processing with Kafka and Spark  "
      ],
      "metadata": {
        "id": "5LmUgD4aQCZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook sets up a complete Stream Processing Lab in Google Colab, inclduing a single broker Kafka cluster, AVRO-based Kafka Producer, AVRO-based Kafka Consumer and Spark Structure Streaming jobs consuming AVRO records from Kafka.  "
      ],
      "metadata": {
        "id": "4w7ZwPPbNpXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YMG_oTxPXFvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbf1430-b720-47ac-873b-ecfcf74f75ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet Faker fastavro kafka-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafka Setup *"
      ],
      "metadata": {
        "id": "q0YIm1vvXOwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile environment.sh\n",
        "#!/usr/bin/bash\n",
        "export KAFKA_BINARY_VERSION='3.7.0'\n",
        "export SCALA_BINARY_VERSION='2.13'\n",
        "export KAFKA_BINARY_VERSION=$KAFKA_BINARY_VERSION\n",
        "export SCALA_BINARY_VERSION=$SCALA_BINARY_VERSION\n",
        "export PATH=$PATH:$PWD/kafka_$SCALA_BINARY_VERSION-$KAFKA_BINARY_VERSION/bin"
      ],
      "metadata": {
        "id": "-mis8YqiXK3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a3dd9f-b4fc-4a94-c19f-230384ae9a20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing environment.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kafka_setup.sh\n",
        "\n",
        "source ./environment.sh\n",
        "echo kafka_$SCALA_BINARY_VERSION-$KAFKA_BINARY_VERSION\n",
        "echo $PATH\n",
        "\n",
        "# Java Setup\n",
        "wget -O- https://apt.corretto.aws/corretto.key | sudo apt-key add -\n",
        "sudo add-apt-repository 'deb https://apt.corretto.aws stable main' -y\n",
        "sudo apt-get -y update; sudo apt-get install -y java-11-amazon-corretto-jdk\n",
        "\n",
        "# Kafka Setup\n",
        "wget https://downloads.apache.org/kafka/${KAFKA_BINARY_VERSION}/kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}.tgz\n",
        "tar xzf kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}.tgz\n",
        "\n",
        "UUID=$(./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/bin/kafka-storage.sh random-uuid)\n",
        "echo \"export UUID=$UUID\" >> ./environment.sh\n",
        "cat environment.sh\n",
        "\n",
        "# Start Kafka Broker\n",
        "\n",
        "echo kafka_$SCALA_BINARY_VERSION-$KAFKA_BINARY_VERSION\n",
        "\n",
        "# offsets.retention.minutes determines how long Kafka retains the commit offsets for consumer groups.\n",
        "echo \"offsets.retention.minutes=300\" >> ./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/config/kraft/server.properties\n",
        "\n",
        "./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/bin/kafka-storage.sh format -t ${UUID} -c ./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/config/kraft/server.properties\n",
        "nohup ./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/bin/kafka-server-start.sh ./kafka_${SCALA_BINARY_VERSION}-${KAFKA_BINARY_VERSION}/config/kraft/server.properties > kafka_server.log &"
      ],
      "metadata": {
        "id": "IttMHpG9X_-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847a7296-8473-4e0d-e79f-522ee914eaab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kafka_setup.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source kafka_setup.sh\n",
        "sleep 10\n",
        "tail -20 kafka_server.log"
      ],
      "metadata": {
        "id": "VK3Eq1ChYDSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59850285-70ca-492e-b099-2795e3ab7dbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kafka_2.13-3.7.0\n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/kafka_2.13-3.7.0/bin\n",
            "--2024-04-14 09:41:25--  https://apt.corretto.aws/corretto.key\n",
            "Resolving apt.corretto.aws (apt.corretto.aws)... 52.84.18.24, 52.84.18.105, 52.84.18.14, ...\n",
            "Connecting to apt.corretto.aws (apt.corretto.aws)|52.84.18.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1695 (1.7K) [binary/octet-stream]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "\r-                     0%[                    ]       0  --.-KB/s               \r-                   100%[===================>]   1.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-14 09:41:25 (687 MB/s) - written to stdout [1695/1695]\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Repository: 'deb https://apt.corretto.aws stable main'\n",
            "Description:\n",
            "Archive for codename: stable components: main\n",
            "More info: https://apt.corretto.aws\n",
            "Adding repository.\n",
            "Adding deb entry to /etc/apt/sources.list.d/archive_uri-https_apt_corretto_aws-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/archive_uri-https_apt_corretto_aws-jammy.list\n",
            "Get:1 https://apt.corretto.aws stable InRelease [10.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 https://apt.corretto.aws stable/main amd64 Packages [17.1 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [808 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n",
            "Fetched 11.6 MB in 2s (5,955 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://apt.corretto.aws/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://apt.corretto.aws stable InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: https://apt.corretto.aws/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  java-11-amazon-corretto-jdk\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 195 MB of archives.\n",
            "After this operation, 327 MB of additional disk space will be used.\n",
            "Get:1 https://apt.corretto.aws stable/main amd64 java-11-amazon-corretto-jdk amd64 1:11.0.22.7-1 [195 MB]\n",
            "Fetched 195 MB in 3s (77.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package java-11-amazon-corretto-jdk:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../java-11-amazon-corretto-jdk_1%3a11.0.22.7-1_amd64.deb ...\n",
            "Unpacking java-11-amazon-corretto-jdk:amd64 (1:11.0.22.7-1) ...\n",
            "Setting up java-11-amazon-corretto-jdk:amd64 (1:11.0.22.7-1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-amazon-corretto/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "--2024-04-14 09:41:45--  https://downloads.apache.org/kafka/3.7.0/kafka_2.13-3.7.0.tgz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.208.237, 135.181.214.104, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.208.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119028138 (114M) [application/x-gzip]\n",
            "Saving to: ‘kafka_2.13-3.7.0.tgz’\n",
            "\n",
            "kafka_2.13-3.7.0.tg 100%[===================>] 113.51M  25.3MB/s    in 5.3s    \n",
            "\n",
            "2024-04-14 09:41:51 (21.6 MB/s) - ‘kafka_2.13-3.7.0.tgz’ saved [119028138/119028138]\n",
            "\n",
            "#!/usr/bin/bash\n",
            "export KAFKA_BINARY_VERSION='3.7.0'\n",
            "export SCALA_BINARY_VERSION='2.13'\n",
            "export KAFKA_BINARY_VERSION=$KAFKA_BINARY_VERSION\n",
            "export SCALA_BINARY_VERSION=$SCALA_BINARY_VERSION\n",
            "export PATH=$PATH:$PWD/kafka_$SCALA_BINARY_VERSION-$KAFKA_BINARY_VERSION/bin\n",
            "export UUID=hAmVTQhhShWANraO5qdR4Q\n",
            "kafka_2.13-3.7.0\n",
            "metaPropertiesEnsemble=MetaPropertiesEnsemble(metadataLogDir=Optional.empty, dirs={/tmp/kraft-combined-logs: EMPTY})\n",
            "Formatting /tmp/kraft-combined-logs with metadata.version 3.7-IV4.\n",
            "nohup: redirecting stderr to stdout\n",
            "\tzookeeper.ssl.protocol = TLSv1.2\n",
            "\tzookeeper.ssl.truststore.location = null\n",
            "\tzookeeper.ssl.truststore.password = null\n",
            "\tzookeeper.ssl.truststore.type = null\n",
            " (kafka.server.KafkaConfig)\n",
            "[2024-04-14 09:42:03,641] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,678] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)\n",
            "[2024-04-14 09:42:03,679] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,680] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)\n",
            "[2024-04-14 09:42:03,680] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)\n",
            "[2024-04-14 09:42:03,680] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)\n",
            "[2024-04-14 09:42:03,682] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,683] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,683] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,683] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,683] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)\n",
            "[2024-04-14 09:42:03,684] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser)\n",
            "[2024-04-14 09:42:03,684] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser)\n",
            "[2024-04-14 09:42:03,684] INFO Kafka startTimeMs: 1713087723683 (org.apache.kafka.common.utils.AppInfoParser)\n",
            "[2024-04-14 09:42:03,686] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a topic \"spotifywrapped\" with 3 partitions and replication factor of 1:"
      ],
      "metadata": {
        "id": "QZoZQNt1csRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "\n",
        "# Delete the existing Kafka topic\n",
        "#kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --topic spotifywrapped --delete\n",
        "\n",
        "# Recreate the Kafka topic with the desired configuration\n",
        "kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --topic spotifywrapped --create --partitions 3 --replication-factor 1\n"
      ],
      "metadata": {
        "id": "UdE5W4oDYJWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64635f0d-fa54-41a1-b219-c24add357511"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic spotifywrapped.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect consumer groups"
      ],
      "metadata": {
        "id": "7j_TuDSy0orC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_kafka_consumers.sh\n",
        "#!/usr/bin/env bash\n",
        "source ./environment.sh\n",
        "\n",
        "echo \"Active Consumer Groups\"\n",
        "while true\n",
        "do\n",
        "date\n",
        "kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --all-groups\n",
        "sleep 1\n",
        "done\n"
      ],
      "metadata": {
        "id": "U87fPnywY0Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96793dd-f5ec-4771-e81a-a006cd44ba2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing check_kafka_consumers.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "chmod +x ./check_kafka_consumers.sh\n",
        "nohup ./check_kafka_consumers.sh > kafka_consumers.log &"
      ],
      "metadata": {
        "id": "_sokQqYj0oQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85857bf-c260-4275-ff5c-dbf7af04d247"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafa Producer of Spotify AVRO Records *"
      ],
      "metadata": {
        "id": "_ewIrwOYY1Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avro_producer.py\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import fastavro\n",
        "from fastavro import parse_schema\n",
        "import pandas as pd\n",
        "from kafka import KafkaProducer\n",
        "import io\n",
        "import random\n",
        "\n",
        "from faker import Faker\n",
        "fake = Faker()\n",
        "Faker.seed(2000)\n",
        "\n",
        "spotify = pd.read_csv('/content/spotifywrapped.csv')\n",
        "\n",
        "schema = {\n",
        "    \"doc\": \"spotify_wrapped\",\n",
        "    \"name\": \"spotify_wrapped_schema\",\n",
        "    \"type\": \"record\",\n",
        "    \"fields\": [\n",
        "        {\"name\": \"user\", \"type\": \"string\"},\n",
        "        {\"name\": \"timestamp\", \"type\": \"long\"},\n",
        "        {\"name\": \"song_id\", \"type\": \"string\"},\n",
        "        {\"name\": \"song_name\", \"type\": \"string\"},\n",
        "        {\"name\": \"genre\", \"type\": \"string\"},\n",
        "        {\"name\": \"artists\", \"type\": \"string\"},\n",
        "        {\"name\": \"duration_ms\", \"type\": \"int\"}\n",
        "    ]\n",
        "}\n",
        "parsed_schema = parse_schema(schema)\n",
        "\n",
        "\n",
        "def simulate_user_activity(start_time: str, end_time: str, genres: list, songs_df: pd.DataFrame = spotify) -> None:\n",
        "    # Generate a random user name\n",
        "    name = fake.name()\n",
        "\n",
        "    # Parse start and end times into datetime objects\n",
        "    start_time = datetime.fromisoformat(start_time)\n",
        "    end_time = datetime.fromisoformat(end_time)\n",
        "\n",
        "    # Generate random timestamps and select a random number of songs per day within the specified time frame\n",
        "    while start_time < end_time:\n",
        "        # Randomly select the number of songs for the day (between 5 and 50)\n",
        "        n_songs = random.randint(5, 50)\n",
        "\n",
        "        # Randomly select songs from specified genres\n",
        "        selected_songs = songs_df[songs_df['genre'].isin(genres)].sample(n=n_songs, replace=True)\n",
        "\n",
        "        # Write Avro records for each selected song\n",
        "        user_data = []\n",
        "        for _, song in selected_songs.iterrows():\n",
        "          start_time = start_time + timedelta(seconds=np.random.randint(30, 86400))\n",
        "          avro_record = {\n",
        "              'user': name,\n",
        "              'timestamp': int(start_time.timestamp() * 1000),  # Convert to milliseconds\n",
        "              'song_id': song['song_id'],\n",
        "              'genre': song['genre'],\n",
        "              'song_name': song['song_name'],  # Corrected from 'trackName' to 'song_name'\n",
        "              'artists': song['artists'],\n",
        "              'duration_ms': song['duration_ms']\n",
        "              }\n",
        "        user_data.append(avro_record)\n",
        "\n",
        "        # Move to the next day\n",
        "        start_time += timedelta(days=1)\n",
        "\n",
        "    return user_data\n",
        "\n",
        "def simulate_spotify_data(start_time: str, end_time: str, genres_list: list, file_name: str = 'multiple_users.avro') -> None:\n",
        "    user_data = []\n",
        "    for i, genres in enumerate(genres_list, start=1):\n",
        "        user = simulate_user_activity(start_time, end_time, genres)\n",
        "        user_data.extend(user)  # Use extend to add all elements of user to user_data\n",
        "\n",
        "    # with open(file_name, 'wb') as out:\n",
        "    #     # Ensure user_data is a list of dictionaries\n",
        "    #     writer(out, parsed_schema, user_data)\n",
        "    # print(\"Users' data saved in file:\", file_name)\n",
        "    return user_data\n",
        "\n",
        "def serialize(message):\n",
        "  print(\"Serialize:\" + str(message))\n",
        "  schemaless_bytes_writer = io.BytesIO()\n",
        "  fastavro.schemaless_writer(schemaless_bytes_writer, schema, message)\n",
        "  return schemaless_bytes_writer.getvalue()\n",
        "\n",
        "\n",
        "\n",
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=['127.0.0.1:9092'],\n",
        "    value_serializer=serialize\n",
        ")\n",
        "\n",
        "import sys\n",
        "topic_name_default=\"spotifywrapped\"\n",
        "if len(sys.argv) > 1:\n",
        "  topic_name = sys.argv[1]\n",
        "else:\n",
        "  topic_name = topic_name_default\n",
        "\n",
        "# generating 1 year of data for 150 users\n",
        "start_time = '2024-01-01T00:00:00+00:00'\n",
        "end_time = '2025-01-01T00:00:00+00:00'\n",
        "\n",
        "def user_generation(n_users=150):\n",
        "    genres = [[\"indie pop\", \"indie rock\", \"alternative rock\", \"folk-pop\"],\n",
        "              [\"hip hop\", \"rap\", \"trap\", \"dfw rap\"],\n",
        "              [\"pop\", \"dance pop\", \"electropop\", \"synth-pop\"],\n",
        "              [\"electronica\", \"edm\", \"house\", \"techno\"],\n",
        "              [\"classic rock\", \"alternative metal\", \"punk\", \"grunge\"]]\n",
        "    all_preferences = []\n",
        "    for i in range(n_users):\n",
        "        all_preferences.append(random.choice(genres))\n",
        "    return all_preferences\n",
        "\n",
        "messages = simulate_spotify_data(start_time, end_time, user_generation())\n",
        "pd.DataFrame(messages).to_csv('/content/spotify_analysis.csv') # for analysis!\n",
        "for message in messages:\n",
        "    print(message)\n",
        "    producer.send(topic_name, value=message)\n",
        "\n",
        "# Flush the producer\n",
        "producer.flush()\n"
      ],
      "metadata": {
        "id": "VLMdt4rxY4Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd61dca-1cc5-4754-e470-f2a41cf74bdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing avro_producer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The producer is sent to the background as it will produce records over a long period of time"
      ],
      "metadata": {
        "id": "tuNCOTRrdgge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python /content/avro_producer.py > /content/avro_producer.log &"
      ],
      "metadata": {
        "id": "SEGeNufsdkKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ed803c-5bb9-4325-9ace-eb200f199f0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe the producer's log for a few seconds. Then, interrupt the cell execution."
      ],
      "metadata": {
        "id": "zIr66quSfDgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sleep 5\n",
        "!tail -20 /content/avro_producer.log"
      ],
      "metadata": {
        "id": "fg0KyKwAe_xo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Kafka Consumer setup *"
      ],
      "metadata": {
        "id": "ut34wBIteKLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avro_consumer.py\n",
        "\n",
        "\n",
        "# Import the required modules\n",
        "from kafka import KafkaConsumer\n",
        "import fastavro\n",
        "import io\n",
        "\n",
        "# Define the schema for the records\n",
        "schema = {\n",
        "    \"doc\": \"spotify_wrapped\",\n",
        "    \"name\": \"spotify_wrapped_schema\",\n",
        "    \"type\": \"record\",\n",
        "    \"fields\": [\n",
        "        {\"name\": \"user\", \"type\": \"string\"},\n",
        "        {\"name\": \"timestamp\", \"type\": \"long\"},\n",
        "        {\"name\": \"song_id\", \"type\": \"string\"},\n",
        "        {\"name\": \"song_name\", \"type\": \"string\"},\n",
        "        {\"name\": \"genre\", \"type\": \"string\"},\n",
        "        {\"name\": \"artists\", \"type\": \"string\"},\n",
        "        {\"name\": \"duration_ms\", \"type\": \"int\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Parse the updated schema\n",
        "from fastavro import parse_schema\n",
        "parsed_updated_schema = parse_schema(schema)\n",
        "\n",
        "# Create a Kafka producer with value serializer\n",
        "def deserialize(message):\n",
        "  # print(\"Deserialize:\" + str(message))\n",
        "\n",
        "  import io\n",
        "  schemaless_bytes_reader = io.BytesIO(message)\n",
        "  try:\n",
        "    record=fastavro.schemaless_reader(schemaless_bytes_reader, schema)\n",
        "    return record\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "    return \"pass\"\n",
        "\n",
        "# Create a Kafka consumer with value deserializer\n",
        "# topic name is a command line argument, if not present it defaults to weather\n",
        "import sys\n",
        "topic_name_default=\"spotifywrapped\"\n",
        "if len(sys.argv) > 1:\n",
        "  topic_name = sys.argv[1]\n",
        "else:\n",
        "  topic_name = topic_name_default\n",
        "\n",
        "consumer = KafkaConsumer(\n",
        "    topic_name,\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    auto_offset_reset='earliest',\n",
        "    enable_auto_commit=True,\n",
        "    group_id='Python_AVRO_Consumer',\n",
        "    value_deserializer=deserialize #lambda v: fastavro.schemaless_reader(io.BytesIO(v), schema)\n",
        ")\n",
        "\n",
        "# Consume messages from the topic and print them\n",
        "for message in consumer:\n",
        "    print(\"=\"*10)\n",
        "    print(message.value)\n"
      ],
      "metadata": {
        "id": "ROYhFV-8eOcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9507848-3b5b-4fce-b397-f26e5b19c64d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing avro_consumer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe how the AVRO consumer receives the messages from the Kafka topic. After a few seconds, interrupt the cell execution:"
      ],
      "metadata": {
        "id": "N_4A0dxCea3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python avro_consumer.py > avro_consumer.log &"
      ],
      "metadata": {
        "id": "mhhBmpcIeZ8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915f6662-d3d0-4839-9cb9-4d04a879fb88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sleep 5\n",
        "!tail -20 avro_consumer.log"
      ],
      "metadata": {
        "id": "qlfDNFL3zff8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef |grep avro"
      ],
      "metadata": {
        "id": "vtfOfs-B1-Ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e47579a-e4e1-4db4-b74e-99e0af827b3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        6551       1  2 09:42 ?        00:00:00 python3 avro_consumer.py\n",
            "root        6992     185  0 09:43 ?        00:00:00 /bin/bash -c ps -ef |grep avro\n",
            "root        6994    6992  0 09:43 ?        00:00:00 grep avro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source ./environment.sh\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list"
      ],
      "metadata": {
        "id": "wZMKCE0J-f5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f75e5c8-f109-40a5-e6f1-e6c6de40020d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python_AVRO_Consumer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group Python_AVRO_Consumer"
      ],
      "metadata": {
        "id": "aAf1bWBV-lYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a78dcb-d28a-4c17-f0d1-15ae1bc56733"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer spotifywrapped  0          36              36              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  1          49              49              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          65              65              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -20 kafka_consumers.log"
      ],
      "metadata": {
        "id": "KVmehwvtyKdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58872ea-fd45-45d2-8c9a-2977907b889a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python_AVRO_Consumer spotifywrapped  1          -               49              -               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          -               65              -               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Sun Apr 14 09:43:02 AM UTC 2024\n",
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer spotifywrapped  0          36              36              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  1          49              49              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          65              65              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Sun Apr 14 09:43:07 AM UTC 2024\n",
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer spotifywrapped  0          36              36              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  1          49              49              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          65              65              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Sun Apr 14 09:43:12 AM UTC 2024\n",
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer spotifywrapped  0          36              36              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  1          49              49              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          65              65              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups"
      ],
      "metadata": {
        "id": "5zptk0YI_5am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf78df8-bb39-47b5-f095-ac9c265657a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer spotifywrapped  0          36              36              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  1          49              49              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer spotifywrapped  2          65              65              0               kafka-python-2.0.2-6cc618a3-403e-4661-b190-a81167306d4b /127.0.0.1      kafka-python-2.0.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Setup\n",
        "\n",
        "Reference: https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html"
      ],
      "metadata": {
        "id": "p0MvrQPoen0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_release='spark-3.5.1'\n",
        "hadoop_version='hadoop3'\n",
        "\n",
        "import os, time\n",
        "start=time.time()\n",
        "os.environ['SPARK_RELEASE']=spark_release\n",
        "os.environ['HADOOP_VERSION']=hadoop_version\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_release}-bin-{hadoop_version}\""
      ],
      "metadata": {
        "id": "yUGK1pfcfdQd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run below commands in google colab\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # install Java8\n",
        "!wget -q http://apache.osuosl.org/spark/${SPARK_RELEASE}/${SPARK_RELEASE}-bin-${HADOOP_VERSION}.tgz # download spark-3.3.X\n",
        "!tar xf ${SPARK_RELEASE}-bin-${HADOOP_VERSION}.tgz # unzip it\n",
        "\n",
        "!pip install -q findspark # install findspark\n",
        "# findspark find your Spark Distribution and sets necessary environment variables\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Check the pyspark version\n",
        "import pyspark\n",
        "print(pyspark.__version__)"
      ],
      "metadata": {
        "id": "1Hm38TuFfdyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024a9d04-32fc-45fb-cb8c-4e473a1ad862"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the configuration details for your Spark job:\n"
      ],
      "metadata": {
        "id": "KKK0qqktP3ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your Spark session. You must define details of the Kafka Cluster to connect to, topic name and consumer group name.\n",
        "\n",
        "- kafka_brokers: List of Kafka bootstrap servers  \n",
        "- topic_name: The Kafka topic to read messages from\n",
        "- consumer_group: This allows you to use different Spark jobs to consume the same topic messages and implement different analytics\n",
        "- schema: the AVRO schema of topic messages"
      ],
      "metadata": {
        "id": "L0Arkhzxg1aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_brokers=\"127.0.0.1:9092\" # Can be a comma-separated list of brokers\n",
        "topic_name=\"spotifywrapped\"\n",
        "\n",
        "# Define the AVRO schema as a string\n",
        "schema = \"\"\"\n",
        "{\n",
        "    \"doc\": \"spotify_wrapped\",\n",
        "    \"name\": \"spotify_wrapped_schema\",\n",
        "    \"type\": \"record\",\n",
        "    \"fields\": [\n",
        "        {\"name\": \"user\", \"type\": \"string\"},\n",
        "        {\"name\": \"timestamp\", \"type\": \"long\"},\n",
        "        {\"name\": \"song_id\", \"type\": \"string\"},\n",
        "        {\"name\": \"song_name\", \"type\": \"string\"},\n",
        "        {\"name\": \"genre\", \"type\": \"string\"},\n",
        "        {\"name\": \"artists\", \"type\": \"string\"},\n",
        "        {\"name\": \"duration_ms\", \"type\": \"int\"}\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "TBTCdSx3g-Ud"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.avro.functions import from_avro\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"StreamingAVROFromKafka\") \\\n",
        "    .config(\"spark.streaming.stopGracefullyOnShutdown\", \"true\") \\\n",
        "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.spark:spark-avro_2.12:3.5.1') \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "JLmxbUrsf_c0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kafka Configuration for reading from Kafka/Event Hub\n",
        "# Kafka source will create a unique group id for each query automatically. The user can set the prefix of the automatically\n",
        "# generated group.id’s via the optional source option groupIdPrefix, default value is “spark-kafka-source”.\n",
        "kafkaConf = {\n",
        "    \"kafka.bootstrap.servers\": kafka_brokers,\n",
        "    # Below settins required if kafka is secured:\n",
        "    # \"kafka.sasl.mechanism\": \"PLAIN\",\n",
        "    # \"kafka.security.protocol\": \"SASL_SSL\",\n",
        "    # \"kafka.sasl.jaas.config\": 'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"Endpoint=sb://eventhubname.servicebus.windows.net/;SharedAccessKeyName=listenpolicyforspark;SharedAccessKey=ckNkSjcyXKGN8FCIRIS3qtkKvW+AEhB6QPaM=;EntityPath=instructortest\";',\n",
        "    \"subscribe\": topic_name, # to read from specific partitions use option: \"assign\": {topic_name:[0,1]})\n",
        "    \"startingOffsets\": \"earliest\", # \"earliest\", \"latest\"\n",
        "    \"enable.auto.commit\": \"true \",\n",
        "    \"groupIdPrefix\": \"Stream_Analytics_\",\n",
        "    \"auto.commit.interval.ms\": \"5000\"\n",
        "}\n",
        "\n",
        "\n",
        "# Read from Event Hub using Kafka\n",
        "df = spark \\\n",
        "    .readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .options(**kafkaConf)"
      ],
      "metadata": {
        "id": "TnuEZtgTgqVG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.load()  # Start reading data from the specified Kafka topic"
      ],
      "metadata": {
        "id": "73pS4AnBift-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "WM_H55a4sacC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9262f98b-8328-4cc7-e19b-de538c9d5213"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deserialize the AVRO messages from the value column\n",
        "df = df.select(from_avro(df.value, schema).alias(\"spotifywrapped\"))\n",
        "\n",
        "# Print the schema of the DataFrame\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "qZF64EK-ifsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995425e0-bfc5-4518-a6fc-22188cd34a83"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- spotifywrapped: struct (nullable = true)\n",
            " |    |-- user: string (nullable = false)\n",
            " |    |-- timestamp: long (nullable = false)\n",
            " |    |-- song_id: string (nullable = false)\n",
            " |    |-- song_name: string (nullable = false)\n",
            " |    |-- genre: string (nullable = false)\n",
            " |    |-- artists: string (nullable = false)\n",
            " |    |-- duration_ms: integer (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##!!!!"
      ],
      "metadata": {
        "id": "XaZPzIc9wXNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Assuming df is your DataFrame containing the AVRO record after flattening\n",
        "df = df.select(\n",
        "    col(\"spotifywrapped.user\").alias(\"user\"),\n",
        "    col(\"spotifywrapped.timestamp\").alias(\"event_timestamp\"),\n",
        "    col(\"spotifywrapped.song_id\").alias(\"song_id\"),\n",
        "    col(\"spotifywrapped.song_name\").alias(\"song_name\"),\n",
        "    col(\"spotifywrapped.genre\").alias(\"genre\"),\n",
        "    col(\"spotifywrapped.artists\").alias(\"artists\"),\n",
        "    col(\"spotifywrapped.duration_ms\").alias(\"duration_ms\")\n",
        ")\n",
        "\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "id": "MzrNKPETLLAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e5e0df-e9b4-4ae8-b6c3-68493537ef69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user: string (nullable = true)\n",
            " |-- event_timestamp: long (nullable = true)\n",
            " |-- song_id: string (nullable = true)\n",
            " |-- song_name: string (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- artists: string (nullable = true)\n",
            " |-- duration_ms: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Assuming df is your DataFrame containing the event_timestamp column\n",
        "df = df.withColumn(\"event_timestamp\", col(\"event_timestamp\").cast(\"timestamp\"))\n",
        "\n",
        "# Verify the data types\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "Oih_kQnJKl6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038a4e40-689e-4fa5-e069-6b60d3987506"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user: string (nullable = true)\n",
            " |-- event_timestamp: timestamp (nullable = true)\n",
            " |-- song_id: string (nullable = true)\n",
            " |-- song_name: string (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- artists: string (nullable = true)\n",
            " |-- duration_ms: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analytical Queries"
      ],
      "metadata": {
        "id": "im0BZXFzjgeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your Spark job and input messages are ready to be worked on. Now, you can apply any transformations required to answer business questions.    "
      ],
      "metadata": {
        "id": "Jx18nWfXQVBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!mkdir checkpoint"
      ],
      "metadata": {
        "id": "VEkMmi234eGt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark Session\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Analytical Queries\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "PzOLwun0MVki"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Query 1:** Top 3 artists, genres, and songs per user:"
      ],
      "metadata": {
        "id": "Fmc0kb9ZjK9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, collect_list, udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "\n",
        "\n",
        "# Aggregate the artists, genres, and songs for each user into lists\n",
        "grouped_df = df.groupBy(\"user\").agg(\n",
        "    collect_list(\"artists\").alias(\"all_artists\"),\n",
        "    collect_list(\"genre\").alias(\"all_genres\"),\n",
        "    collect_list(\"song_name\").alias(\"all_songs\")\n",
        ")\n",
        "\n",
        "# Define a custom aggregation function to select the top items for each user\n",
        "def select_top_items(items_list):\n",
        "    sorted_items = sorted(items_list, key=lambda x: -items_list.count(x))\n",
        "    return list(dict.fromkeys(sorted_items[:1]))\n",
        "\n",
        "# Define the UDFs (User Defined Functions) for artists, genres, and songs\n",
        "select_top_udf = udf(select_top_items, ArrayType(StringType()))\n",
        "\n",
        "# Apply the UDFs to select the top artist, genre, and song for each user\n",
        "top_df = grouped_df.select(\n",
        "    col(\"user\"),\n",
        "    select_top_udf(col(\"all_artists\")).alias(\"top_artist\"),\n",
        "    select_top_udf(col(\"all_genres\")).alias(\"top_genre\"),\n",
        "    select_top_udf(col(\"all_songs\")).alias(\"top_song\")\n",
        ")\n",
        "\n",
        "# Write the results to console as a streaming query\n",
        "query_name = 'topArtistGenreSong'\n",
        "query = top_df \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(query_name) \\\n",
        "    .start()\n",
        "\n",
        "time.sleep(300)\n",
        "\n",
        "query.stop()"
      ],
      "metadata": {
        "id": "ZPlKh4HUioVP"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "# Function to display the contents periodically\n",
        "def display_streaming_results(query_name, interval_seconds=10, iterations=5):\n",
        "    \"\"\"\n",
        "    Displays the streaming query results periodically.\n",
        "\n",
        "    Parameters:\n",
        "    query_name (str): The name of the in-memory table to query.\n",
        "    interval_seconds (int): How long to wait between each display.\n",
        "    iterations (int): How many times to display the results.\n",
        "    \"\"\"\n",
        "    for _ in range(iterations):\n",
        "        results_df = spark.table(query_name)\n",
        "        results_df.show(truncate=False)\n",
        "        sleep(interval_seconds)\n",
        "\n",
        "# Assuming 'topArtistGenreSong2' is the name of your in-memory table\n",
        "display_streaming_results(\"topArtistGenreSong\", interval_seconds=30, iterations=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amhechHFjms7",
        "outputId": "9c0193d6-eca7-4b4f-8af4-b986a3f01ea8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------------+-------------------+------------------------------------------------+\n",
            "|user             |top_artist     |top_genre          |top_song                                        |\n",
            "+-----------------+---------------+-------------------+------------------------------------------------+\n",
            "|Brianna Barrett  |[Lauv]         |[pop]              |[Modern Loneliness]                             |\n",
            "|Aaron Flores     |[Lauv]         |[pop]              |[Summer Nights]                                 |\n",
            "|Hannah Ross      |[WILD]         |[folk-pop]         |[Here We Go]                                    |\n",
            "|Elizabeth Mayer  |[Post Malone]  |[dfw rap]          |[I Like You (A Happier Song) (with Doja Cat)]   |\n",
            "|Maria Webb       |[Tommy Lefroy] |[indie pop]        |[Trashfire]                                     |\n",
            "|Teresa Washington|[Linkin Park]  |[alternative metal]|[Leave Out All The Rest]                        |\n",
            "|Marisa Robinson  |[LULLANAS]     |[folk-pop]         |[Queen of Disaster]                             |\n",
            "|Chloe Liu        |[Post Malone]  |[dfw rap]          |[Hollywood's Bleeding]                          |\n",
            "|Dylan Reid       |[Ayo & Teo]    |[trap]             |[Rolex]                                         |\n",
            "|Catherine Elliott|[PJ Harvey]    |[alternative rock] |[Good Fortune]                                  |\n",
            "|Michael Baker    |[Travis Scott] |[hip hop]          |[The Plan - From the Motion Picture \"TENET\"]    |\n",
            "|Jeffrey Walton   |[Jonas Blue]   |[pop]              |[Mama - Syn Cole Remix]                         |\n",
            "|Dr. Kevin Mercer |[Benny Benassi]|[edm]              |[Cinema - Skrillex Remix]                       |\n",
            "|Jose Walker      |[Linkin Park]  |[alternative metal]|[When They Come for Me]                         |\n",
            "|Ryan Hernandez   |[blackbear]    |[pop]              |[u love u (with Tate McRae)]                    |\n",
            "|Randy Macdonald  |[DJ Snake]     |[edm]              |[Taki Taki (with Selena Gomez, Ozuna & Cardi B)]|\n",
            "|David Meyers     |[LULLANAS]     |[folk-pop]         |[Queen of Disaster]                             |\n",
            "|Aaron Robinson   |[Bruno Mars]   |[dance pop]        |[That's What I Like]                            |\n",
            "|Brittany Lester  |[Bazzi]        |[pop]              |[Why]                                           |\n",
            "|Jeremiah Hart    |[Grouplove]    |[indie rock]       |[Raspberry]                                     |\n",
            "+-----------------+---------------+-------------------+------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "def aggregate_top_choices(query_name, sleep_time=10, iterations=5):\n",
        "    \"\"\"\n",
        "    Aggregates and displays the top choices from streaming data periodically.\n",
        "\n",
        "    Parameters:\n",
        "    query_name (str): The name of the in-memory table to query.\n",
        "    sleep_time (int): Seconds to wait between each query.\n",
        "    iterations (int): Number of times to query and display results.\n",
        "    \"\"\"\n",
        "    for _ in range(iterations):\n",
        "        # Read the latest snapshot of the streaming data from the in-memory table\n",
        "        results_df = spark.table(query_name)\n",
        "\n",
        "        # Aggregate to find the most common top artists, genres, and songs\n",
        "        top_artists = results_df.groupBy(\"top_artist\").agg(count(\"top_artist\").alias(\"count_artist\")).orderBy(col(\"count_artist\").desc()).limit(3)\n",
        "        top_genres = results_df.groupBy(\"top_genre\").agg(count(\"top_genre\").alias(\"count_genre\")).orderBy(col(\"count_genre\").desc()).limit(3)\n",
        "        top_songs = results_df.groupBy(\"top_song\").agg(count(\"top_song\").alias(\"count_song\")).orderBy(col(\"count_song\").desc()).limit(3)\n",
        "\n",
        "        # Display the results\n",
        "        print(\"Top Artists:\")\n",
        "        top_artists.show(truncate=False)\n",
        "        print(\"Top Genres:\")\n",
        "        top_genres.show(truncate=False)\n",
        "        print(\"Top Songs:\")\n",
        "        top_songs.show(truncate=False)\n",
        "\n",
        "        sleep(sleep_time)\n",
        "\n",
        "aggregate_top_choices(\"topArtistGenreSong\", sleep_time=30, iterations=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVssbs2iD5_q",
        "outputId": "536d5f7e-5617-450d-ca01-fdf9c1d2feab"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Artists:\n",
            "+-------------+------------+\n",
            "|top_artist   |count_artist|\n",
            "+-------------+------------+\n",
            "|[Linkin Park]|16          |\n",
            "|[Post Malone]|9           |\n",
            "|[NF]         |8           |\n",
            "+-------------+------------+\n",
            "\n",
            "Top Genres:\n",
            "+-------------------+-----------+\n",
            "|top_genre          |count_genre|\n",
            "+-------------------+-----------+\n",
            "|[pop]              |25         |\n",
            "|[edm]              |24         |\n",
            "|[alternative metal]|21         |\n",
            "+-------------------+-----------+\n",
            "\n",
            "Top Songs:\n",
            "+--------------------------------------+----------+\n",
            "|top_song                              |count_song|\n",
            "+--------------------------------------+----------+\n",
            "|[Renegade]                            |4         |\n",
            "|[Plain Jane REMIX (feat. Nicki Minaj)]|3         |\n",
            "|[Queen of Disaster]                   |3         |\n",
            "+--------------------------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert table to DF\n",
        "top_df = spark.sql(\"SELECT * FROM topArtistGenreSong\")\n",
        "\n",
        "# Save df\n",
        "top_df = top_df.toPandas()\n",
        "top_df.to_csv('top_artist_genre_song.csv', index=False)"
      ],
      "metadata": {
        "id": "QzfPru9IKMOb"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Query 2:** Peak Listening Times\n",
        "- When users are most actively listening to music"
      ],
      "metadata": {
        "id": "Fc8j15V_qJXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import window, col, count\n",
        "\n",
        "# Directly use 'event_timestamp' as it's already a timestamp type for windowing:\n",
        "peak_listening_times = df \\\n",
        "    .groupBy(\n",
        "        window(col(\"event_timestamp\"), \"1 hour\")\n",
        "    ) \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"plays\")\n",
        "    ) \\\n",
        "    .orderBy(\"window.start\")  # Ordering by the start of the window\n"
      ],
      "metadata": {
        "id": "l6Nzb6XuqRtI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = peak_listening_times \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"peakListeningTimesTable\") \\\n",
        "    .start()\n",
        "\n",
        "sleep(60)"
      ],
      "metadata": {
        "id": "1g_IT6EB62VT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now query the in-memory table\n",
        "display_df = spark.sql(\"SELECT * FROM peakListeningTimesTable\")\n",
        "display_df.show(truncate=False)\n",
        "\n",
        "# Remember to stop the stream after you're done to free resources\n",
        "query.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbdHEnWCIhOd",
        "outputId": "f7bf38dc-c33c-4311-a98b-8d0bad300e27"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------+-----+\n",
            "|window                                        |plays|\n",
            "+----------------------------------------------+-----+\n",
            "|{+56969-02-13 21:00:00, +56969-02-13 22:00:00}|1    |\n",
            "|{+56969-07-19 11:00:00, +56969-07-19 12:00:00}|1    |\n",
            "|{+56969-09-15 16:00:00, +56969-09-15 17:00:00}|1    |\n",
            "|{+56969-09-16 23:00:00, +56969-09-17 00:00:00}|1    |\n",
            "|{+56969-10-19 11:00:00, +56969-10-19 12:00:00}|1    |\n",
            "|{+56970-02-02 17:00:00, +56970-02-02 18:00:00}|1    |\n",
            "|{+56970-02-23 19:00:00, +56970-02-23 20:00:00}|1    |\n",
            "|{+56970-04-01 16:00:00, +56970-04-01 17:00:00}|1    |\n",
            "|{+56970-08-07 19:00:00, +56970-08-07 20:00:00}|1    |\n",
            "|{+56970-11-09 16:00:00, +56970-11-09 17:00:00}|1    |\n",
            "|{+56970-12-14 16:00:00, +56970-12-14 17:00:00}|1    |\n",
            "|{+56971-04-09 07:00:00, +56971-04-09 08:00:00}|1    |\n",
            "|{+56971-05-30 22:00:00, +56971-05-30 23:00:00}|1    |\n",
            "|{+56971-08-29 01:00:00, +56971-08-29 02:00:00}|1    |\n",
            "|{+56971-10-17 16:00:00, +56971-10-17 17:00:00}|1    |\n",
            "|{+56971-11-23 00:00:00, +56971-11-23 01:00:00}|1    |\n",
            "|{+56972-06-08 12:00:00, +56972-06-08 13:00:00}|1    |\n",
            "|{+56972-09-01 15:00:00, +56972-09-01 16:00:00}|1    |\n",
            "|{+56972-12-11 08:00:00, +56972-12-11 09:00:00}|1    |\n",
            "|{+56973-01-27 21:00:00, +56973-01-27 22:00:00}|1    |\n",
            "+----------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import hour, date_format\n",
        "\n",
        "# Load the data from the in-memory table\n",
        "peak_times_df = spark.sql(\"SELECT * FROM peakListeningTimesTable\")\n",
        "\n",
        "# Extract hour from the window start time and aggregate to find the most common peak hours\n",
        "most_common_hours = peak_times_df.withColumn(\"hour\", hour(col(\"window.start\"))) \\\n",
        "    .groupBy(\"hour\") \\\n",
        "    .agg(count(\"*\").alias(\"count\")) \\\n",
        "    .orderBy(col(\"count\").desc())\n",
        "\n",
        "# Show the results\n",
        "most_common_hours.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJeaXSLrEiDT",
        "outputId": "89ea9251-f050-46bc-ed69-f8e00cb898e6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|hour|count|\n",
            "+----+-----+\n",
            "|16  |10   |\n",
            "|10  |10   |\n",
            "|12  |8    |\n",
            "|22  |8    |\n",
            "|2   |8    |\n",
            "|11  |8    |\n",
            "|18  |7    |\n",
            "|23  |7    |\n",
            "|3   |7    |\n",
            "|17  |6    |\n",
            "|19  |6    |\n",
            "|15  |6    |\n",
            "|20  |6    |\n",
            "|6   |6    |\n",
            "|5   |6    |\n",
            "|1   |6    |\n",
            "|0   |6    |\n",
            "|8   |6    |\n",
            "|9   |5    |\n",
            "|21  |5    |\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Interpretation:***\n",
        "- Most common hours: 4pm and 10pm\n",
        "- Evening and late night trends: at times like 10pm (22) and 11pm (23), suggest there is activity late in the evening, potentially as people relax or unwind before bed.\n",
        "- Morning hours (10 & 11) and mid-afternoon hours (16) - key times when users are active on the platform, potentially during breaks or commutes.\n"
      ],
      "metadata": {
        "id": "c0dO34EhEvX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import hour\n",
        "\n",
        "# Extract hour and prepare the DataFrame\n",
        "hourly_counts = spark.sql(\"\"\"\n",
        "SELECT hour(window.start) AS hour, sum(plays) as count\n",
        "FROM peakListeningTimesTable\n",
        "GROUP BY hour(window.start)\n",
        "ORDER BY hour(window.start)\n",
        "\"\"\")\n",
        "\n",
        "# Convert to Pandas DataFrame for plotting\n",
        "pandas_df = hourly_counts.toPandas()\n"
      ],
      "metadata": {
        "id": "QQkK8xmgFtIa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(pandas_df['hour'], pandas_df['count'], color='blue')\n",
        "plt.xlabel('Hour of the Day')\n",
        "plt.ylabel('Number of Plays')\n",
        "plt.title('Peak Listening Times')\n",
        "plt.xticks(pandas_df['hour'])  # Ensure x-ticks represent each hour correctly\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "0Yrcma2CGD2j",
        "outputId": "5477c663-ca21-4ded-afae-3c056b94af83"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "pandas_df.to_csv('peak_times_df.csv', index=False)"
      ],
      "metadata": {
        "id": "ZOqBok4VQOCb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Query 3:** User Genre Preferences Over Time\n",
        "- Calculates weekly counts of song plays per genre for each user and stores results in an in-memory table.\n",
        "- Handles late data with a 7-day watermark."
      ],
      "metadata": {
        "id": "YnB8hCNKm3jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import window, col, count\n",
        "import time\n",
        "\n",
        "df_with_watermark = df.withWatermark(\"event_timestamp\", \"7 days\")\n",
        "\n",
        "user_genre_preferences = df_with_watermark.groupBy(\n",
        "    col(\"user\"),\n",
        "    window(col(\"event_timestamp\"), \"1 week\"),\n",
        "    col(\"genre\")\n",
        ").agg(count(\"song_id\").alias(\"song_plays\"))\n",
        "\n",
        "query = user_genre_preferences \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"user_genre_preferences_table\") \\\n",
        "    .start()\n",
        "\n",
        "time.sleep(300)"
      ],
      "metadata": {
        "id": "9PsT_ojGJdfQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sorted_results():\n",
        "    sorted_df = spark.sql(\"\"\"\n",
        "        SELECT user, window, genre, song_plays\n",
        "        FROM user_genre_preferences_table\n",
        "        ORDER BY user, window.start, song_plays DESC\n",
        "    \"\"\")\n",
        "    sorted_df.show(truncate=False)\n",
        "\n",
        "# Display results after waiting\n",
        "display_sorted_results()\n",
        "\n",
        "# Stop the query after checking the output\n",
        "query.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqAzhFywJnGz",
        "outputId": "c6ec0a45-7dea-4b17-b6eb-3f1e298cd006"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------------------------------------+-----------------+----------+\n",
            "|user             |window                                        |genre            |song_plays|\n",
            "+-----------------+----------------------------------------------+-----------------+----------+\n",
            "|Aaron Flores     |{+56978-09-24 00:00:00, +56978-10-01 00:00:00}|pop              |1         |\n",
            "|Aaron Robinson   |{+56976-10-10 00:00:00, +56976-10-17 00:00:00}|dance pop        |1         |\n",
            "|Adam Horn        |{+56984-08-19 00:00:00, +56984-08-26 00:00:00}|hip hop          |1         |\n",
            "|Adam Velazquez   |{+56969-10-19 00:00:00, +56969-10-26 00:00:00}|indie pop        |1         |\n",
            "|Alan Martinez    |{+56970-02-22 00:00:00, +56970-03-01 00:00:00}|alternative metal|1         |\n",
            "|Alyssa Evans DDS |{+56997-05-25 00:00:00, +56997-06-01 00:00:00}|electropop       |1         |\n",
            "|Alyssa Jones     |{+56990-10-21 00:00:00, +56990-10-28 00:00:00}|alternative metal|1         |\n",
            "|Amanda Russell   |{+56979-09-23 00:00:00, +56979-09-30 00:00:00}|edm              |1         |\n",
            "|Andrew Anderson  |{+57012-07-09 00:00:00, +57012-07-16 00:00:00}|hip hop          |1         |\n",
            "|Andrew Freeman   |{+56972-08-27 00:00:00, +56972-09-03 00:00:00}|indie pop        |1         |\n",
            "|April Wilson     |{+56969-07-13 00:00:00, +56969-07-20 00:00:00}|dance pop        |1         |\n",
            "|Ashley White     |{+56975-02-23 00:00:00, +56975-03-02 00:00:00}|dfw rap          |1         |\n",
            "|Ashley Williams  |{+56978-04-02 00:00:00, +56978-04-09 00:00:00}|edm              |1         |\n",
            "|Brad Walters     |{+56978-04-23 00:00:00, +56978-04-30 00:00:00}|classic rock     |1         |\n",
            "|Brenda Moreno    |{+56974-06-30 00:00:00, +56974-07-07 00:00:00}|dfw rap          |1         |\n",
            "|Brianna Barrett  |{+56971-08-29 00:00:00, +56971-09-05 00:00:00}|pop              |1         |\n",
            "|Brittany Lester  |{+56981-09-27 00:00:00, +56981-10-04 00:00:00}|pop              |1         |\n",
            "|Brittany Martinez|{+56975-08-17 00:00:00, +56975-08-24 00:00:00}|alternative metal|1         |\n",
            "|Bryan Chavez     |{+56974-01-13 00:00:00, +56974-01-20 00:00:00}|indie pop        |1         |\n",
            "|Carla Young      |{+56971-04-04 00:00:00, +56971-04-11 00:00:00}|alternative metal|1         |\n",
            "+-----------------+----------------------------------------------+-----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_genre_popularity = spark.sql(\"\"\"\n",
        "    SELECT genre, SUM(song_plays) AS total_plays\n",
        "    FROM user_genre_preferences_table\n",
        "    GROUP BY genre\n",
        "    ORDER BY total_plays DESC\n",
        "\"\"\")\n",
        "\n",
        "# Display overall genre popularity\n",
        "overall_genre_popularity.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPV3LTvnJMI4",
        "outputId": "a3af789d-1c90-4382-a4be-d912f7eef89c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+\n",
            "|genre            |total_plays|\n",
            "+-----------------+-----------+\n",
            "|pop              |25         |\n",
            "|edm              |24         |\n",
            "|alternative metal|21         |\n",
            "|folk-pop         |14         |\n",
            "|indie pop        |14         |\n",
            "|hip hop          |13         |\n",
            "|dfw rap          |10         |\n",
            "|dance pop        |8          |\n",
            "|alternative rock |8          |\n",
            "|classic rock     |4          |\n",
            "|electropop       |2          |\n",
            "|indie rock       |2          |\n",
            "|trap             |2          |\n",
            "|electronica      |2          |\n",
            "|grunge           |1          |\n",
            "+-----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save df\n",
        "weekly_data = overall_genre_popularity.toPandas()\n",
        "weekly_data.to_csv('weekly_genre_trends.csv', index=False)"
      ],
      "metadata": {
        "id": "SYzSIHO9RHcp"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Interpretation***\n",
        "- Pop - most popular genre throughout the year (25 plays)\n",
        "- EDM - closely follows (24 plays)\n",
        "- Alternative metal - (21 plays)\n",
        "- Niche genres like Electropop, Indie Rock, and Electronica have fewer plays - suggest more specific audience segments"
      ],
      "metadata": {
        "id": "u4r_J2V8MjQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, month, count\n",
        "\n",
        "# Modify the DataFrame to group by month, and sum the song plays per genre\n",
        "monthly_genre_trends = df_with_watermark.groupBy(\n",
        "    month(col(\"event_timestamp\")).alias(\"month\"),\n",
        "    col(\"genre\")\n",
        ").agg(count(\"song_id\").alias(\"total_plays\"))\n",
        "\n",
        "# Start the stream to write the aggregated data to an in-memory table\n",
        "query_monthly = monthly_genre_trends \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"monthly_genre_trends_table3\") \\\n",
        "    .start()\n",
        "\n",
        "# Allow some time for data to accumulate\n",
        "time.sleep(300)  # Adjust based on your environment\n",
        "\n",
        "# Query and display the results from the in-memory table\n",
        "monthly_trends_df = spark.sql(\"\"\"\n",
        "    SELECT month, genre, total_plays\n",
        "    FROM monthly_genre_trends_table\n",
        "    ORDER BY month, total_plays DESC\n",
        "\"\"\")\n",
        "monthly_trends_df.show(truncate=False)\n",
        "\n",
        "# Stop the stream after checking the output\n",
        "query_monthly.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jER-SFmiJknW",
        "outputId": "23b68f49-cef7-49d4-c8ca-b44280c8078b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+-----------+\n",
            "|month|genre            |total_plays|\n",
            "+-----+-----------------+-----------+\n",
            "|1    |dance pop        |1          |\n",
            "|1    |pop              |1          |\n",
            "|1    |alternative rock |1          |\n",
            "|1    |indie pop        |1          |\n",
            "|1    |edm              |1          |\n",
            "|1    |edm              |1          |\n",
            "|1    |alternative rock |1          |\n",
            "|2    |alternative metal|1          |\n",
            "|2    |dfw rap          |1          |\n",
            "|2    |pop              |1          |\n",
            "|2    |hip hop          |1          |\n",
            "|2    |alternative metal|1          |\n",
            "|2    |alternative metal|1          |\n",
            "|2    |folk-pop         |1          |\n",
            "|2    |alternative metal|1          |\n",
            "|2    |pop              |1          |\n",
            "|2    |pop              |1          |\n",
            "|2    |indie rock       |1          |\n",
            "|2    |dfw rap          |1          |\n",
            "|2    |edm              |1          |\n",
            "+-----+-----------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "static_df = spark.sql(\"SELECT month, genre, total_plays FROM monthly_genre_trends_table ORDER BY month, total_plays DESC\")\n",
        "\n",
        "# Convert to Pandas DataFrame for further analysis\n",
        "monthly_trends_pd = static_df.toPandas()\n",
        "\n",
        "# Get the top genre per month using Pandas\n",
        "top_genre_per_month = monthly_trends_pd.groupby('month').apply(lambda x: x.nlargest(1, 'total_plays')).reset_index(drop=True)\n",
        "\n",
        "# Display the Pandas DataFrame\n",
        "print(top_genre_per_month)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTX-iGwZOnNM",
        "outputId": "2c639f25-81b4-4219-d150-2a60deea9084"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    month              genre  total_plays\n",
            "0       1          dance pop            1\n",
            "1       2                pop            1\n",
            "2       3  alternative metal            1\n",
            "3       4                edm            2\n",
            "4       5                edm            1\n",
            "5       6  alternative metal            1\n",
            "6       7                edm            1\n",
            "7       8                pop            2\n",
            "8       9                pop            1\n",
            "9      10  alternative metal            1\n",
            "10     11           folk-pop            1\n",
            "11     12  alternative metal            1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "top_genre_per_month = pd.DataFrame({\n",
        "    'month': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
        "    'genre': [\n",
        "        'dance pop', 'pop', 'alternative metal', 'edm', 'edm',\n",
        "        'alternative metal', 'edm', 'pop', 'pop', 'alternative metal',\n",
        "        'folk-pop', 'alternative metal'\n",
        "    ],\n",
        "    'total_plays': [1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1]\n",
        "})\n",
        "\n",
        "# Map the month number to the month name for better readability\n",
        "month_map = {1: 'January', 2: 'February', 3: 'March', 4: 'April',\n",
        "             5: 'May', 6: 'June', 7: 'July', 8: 'August',\n",
        "             9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
        "top_genre_per_month['month'] = top_genre_per_month['month'].map(month_map)\n",
        "\n",
        "# Reorder the DataFrame based on the month\n",
        "top_genre_per_month = top_genre_per_month.set_index('month').sort_index()\n",
        "\n",
        "# For visual display in Jupyter Notebook, we can use the display function\n",
        "display(top_genre_per_month)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "3m6d3CqCPkWs",
        "outputId": "45117017-ad1a-4fc9-f124-2ed96cb719e5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       genre  total_plays\n",
              "month                                    \n",
              "April                    edm            2\n",
              "August                   pop            2\n",
              "December   alternative metal            1\n",
              "February                 pop            1\n",
              "January            dance pop            1\n",
              "July                     edm            1\n",
              "June       alternative metal            1\n",
              "March      alternative metal            1\n",
              "May                      edm            1\n",
              "November            folk-pop            1\n",
              "October    alternative metal            1\n",
              "September                pop            1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da82b537-356f-4110-a4f6-b92f8fa1e714\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>total_plays</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>April</th>\n",
              "      <td>edm</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>August</th>\n",
              "      <td>pop</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>December</th>\n",
              "      <td>alternative metal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>February</th>\n",
              "      <td>pop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>January</th>\n",
              "      <td>dance pop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>July</th>\n",
              "      <td>edm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>June</th>\n",
              "      <td>alternative metal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>March</th>\n",
              "      <td>alternative metal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>edm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>November</th>\n",
              "      <td>folk-pop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>October</th>\n",
              "      <td>alternative metal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>September</th>\n",
              "      <td>pop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da82b537-356f-4110-a4f6-b92f8fa1e714')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da82b537-356f-4110-a4f6-b92f8fa1e714 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da82b537-356f-4110-a4f6-b92f8fa1e714');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d1b8b1c-4ace-41b9-a843-6ccaa02dd330\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d1b8b1c-4ace-41b9-a843-6ccaa02dd330')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d1b8b1c-4ace-41b9-a843-6ccaa02dd330 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_genre_per_month",
              "summary": "{\n  \"name\": \"top_genre_per_month\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"October\",\n          \"November\",\n          \"April\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"pop\",\n          \"folk-pop\",\n          \"alternative metal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_plays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "monthly_trends_pd.to_csv(\"monthly_genre_trends.csv\", index=True, header=True)"
      ],
      "metadata": {
        "id": "NWijRe0ZMJcE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wzoNKza2l0B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Get the list of active streaming queries\n",
        "active_queries = spark.streams.active\n",
        "\n",
        "# Check if there are any active queries\n",
        "if not active_queries:\n",
        "    print(\"No active streaming queries.\")\n",
        "else:\n",
        "    # Print details about each active query\n",
        "    for query in active_queries:\n",
        "        print(f\"Query Name: {query.name}\")\n",
        "        print(f\"Query ID: {query.id}\")\n",
        "        print(f\"Last Progress: {query.lastProgress}\")\n",
        "        print(f\"Query Status: {query.status}\")\n",
        "        print(f\"Is Query Active: {query.isActive}\")  # Notice the removal of the parentheses\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "Jn0CaKocj3DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86192f6-28d0-4a38-bf2b-9376f081389b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Name: topArtistGenreSong\n",
            "Query ID: 247b034a-ad35-4c2a-95ff-ef2f410a1e80\n",
            "Last Progress: {'id': '247b034a-ad35-4c2a-95ff-ef2f410a1e80', 'runId': '74dbe1e5-d280-449b-a5a1-b68d36c998f4', 'name': 'topArtistGenreSong', 'timestamp': '2024-04-13T21:18:51.291Z', 'batchId': 1, 'numInputRows': 0, 'inputRowsPerSecond': 0.0, 'processedRowsPerSecond': 0.0, 'durationMs': {'latestOffset': 3, 'triggerExecution': 3}, 'stateOperators': [{'operatorName': 'stateStoreSave', 'numRowsTotal': 150, 'numRowsUpdated': 0, 'allUpdatesTimeMs': 1071, 'numRowsRemoved': 0, 'allRemovalsTimeMs': 1, 'commitTimeMs': 752, 'memoryUsedBytes': 58184, 'numRowsDroppedByWatermark': 0, 'numShufflePartitions': 4, 'numStateStoreInstances': 4, 'customMetrics': {'loadedMapCacheHitCount': 0, 'loadedMapCacheMissCount': 0, 'stateOnCurrentVersionSizeBytes': 57608}}], 'sources': [{'description': 'KafkaV2[Subscribe[spotifywrapped]]', 'startOffset': {'spotifywrapped': {'2': 49, '1': 45, '0': 56}}, 'endOffset': {'spotifywrapped': {'2': 49, '1': 45, '0': 56}}, 'latestOffset': {'spotifywrapped': {'2': 49, '1': 45, '0': 56}}, 'numInputRows': 0, 'inputRowsPerSecond': 0.0, 'processedRowsPerSecond': 0.0, 'metrics': {'avgOffsetsBehindLatest': '0.0', 'maxOffsetsBehindLatest': '0', 'minOffsetsBehindLatest': '0'}}], 'sink': {'description': 'MemorySink', 'numOutputRows': 0}}\n",
            "Query Status: {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
            "Is Query Active: True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all tables in the current database\n",
        "spark.catalog.listTables()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRrRa_1aPvxX",
        "outputId": "4eb1ba93-9cdf-41ca-b89f-2fbeebcb2f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='peakListeningTimesTable', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='topArtistGenreSong', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='user_genre_preferences_table', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafka topic to Parquet files"
      ],
      "metadata": {
        "id": "C_Z4WDkT59F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!mkdir output"
      ],
      "metadata": {
        "id": "kuEXTnWwDfr3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "query_name='parquet'\n",
        "query_parquet = df.writeStream \\\n",
        "        .format(\"parquet\") \\\n",
        "        .option(\"checkpointLocation\",\"checkpoint2\") \\\n",
        "        .option(\"path\", \"output\") \\\n",
        "        .queryName(query_name) \\\n",
        "        .trigger(processingTime='20 seconds') \\\n",
        "        .start()"
      ],
      "metadata": {
        "id": "AVNUQZeKDVyA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!ls -lth output |head -10"
      ],
      "metadata": {
        "id": "xHljZqEeFMP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f8be59-a60d-4195-a160-2c67482ca802",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.0K\n",
            "-rw-r--r-- 1 root root    0 Mar 13 17:04 part-00000-5b219372-8376-427d-b191-1a0f59a03ac2-c000.snappy.parquet\n",
            "drwxr-xr-x 2 root root 4.0K Mar 13 17:04 _spark_metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Spark jobs using Kafka as input  "
      ],
      "metadata": {
        "id": "KO-0JCDxPNP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark Queries use a low level Kafka API and do not show up as consumer groups.\n",
        "\n",
        "\n",
        "Spark Streaming integrates with Kafka using two approaches: the receiver-based approach (Spark 1.2) and the direct stream (or direct API) approach (Spark v1.3+).\n",
        "\n",
        "**Receiver-based Approach**: In earlier versions of Spark Streaming (before 1.3), Kafka integration was primarily done using receivers. This approach used Kafka's high-level consumer API, where data was received by Kafka Receivers running in Spark executors. The received data was stored in Spark’s memory as well as in Write Ahead Logs (WALs) for fault tolerance. This approach did use consumer groups as part of its operation because it utilized Kafka's high-level API​.  \n",
        "\n",
        "![](https://www.databricks.com/wp-content/uploads/2015/03/Screen-Shot-2015-03-29-at-10.11.42-PM.png)\n",
        "\n",
        "**Direct Stream Approach**: Introduced in Spark 1.3, the direct stream approach does not use receivers. Instead, it periodically queries Kafka for the latest offsets and processes the data directly from Kafka, similar to reading files from a file system. This approach improves efficiency and ensures exactly-once semantics by eliminating the need for WALs and receivers. However, it uses the Kafka Simple Consumer API and manages offsets within Spark itself, rather than using Kafka's consumer groups and offset management features.    \n",
        "\n",
        "![](https://www.databricks.com/wp-content/uploads/2015/03/Screen-Shot-2015-03-29-at-10.14.11-PM.png)\n",
        "\n",
        "Reference: https://www.databricks.com/blog/2015/03/30/improvements-to-kafka-integration-of-spark-streaming.html"
      ],
      "metadata": {
        "id": "fniDJAgfJxmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups"
      ],
      "metadata": {
        "id": "PafURvZxDVpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37c2ed7-2156-425d-b944-8ade4135952b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GROUP                TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                             HOST            CLIENT-ID\n",
            "Python_AVRO_Consumer weather         0          50              50              0               kafka-python-2.0.2-cb2c17de-9d9d-4939-a425-9312e645b9ee /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer weather         1          51              52              1               kafka-python-2.0.2-cb2c17de-9d9d-4939-a425-9312e645b9ee /127.0.0.1      kafka-python-2.0.2\n",
            "Python_AVRO_Consumer weather         2          41              41              0               kafka-python-2.0.2-cb2c17de-9d9d-4939-a425-9312e645b9ee /127.0.0.1      kafka-python-2.0.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Get the list of active streaming queries\n",
        "active_queries = spark.streams.active\n",
        "\n",
        "# Print details about each active query\n",
        "for query in active_queries:\n",
        "    print(f\"Query Name: {query.name}\")\n",
        "    print(f\"Query ID: {query.id}\")\n",
        "    print(f\"Query Status: {query.status}\")\n",
        "    print(f\"Is Query Active: {query.isActive}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "yiTN40aZD7RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3494af2-2f1c-4015-b7e8-361d3729298f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Name: snowy\n",
            "Query ID: 5a7b71b8-e980-4832-9752-b1552c5eb393\n",
            "Query Status: {'message': 'Getting offsets from KafkaV2[Subscribe[weather]]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
            "Is Query Active: True\n",
            "--------------------------------------------------\n",
            "Query Name: parquet\n",
            "Query ID: b2434c86-918e-4b5f-b9d6-a925da270984\n",
            "Query Status: {'message': 'Waiting for next trigger', 'isDataAvailable': True, 'isTriggerActive': False}\n",
            "Is Query Active: True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Warehouse"
      ],
      "metadata": {
        "id": "GCJstxwgPRKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The spark-warehouse directory is the default location where Spark SQL stores its metadata and table data. When you use the toTable method in Structured Streaming or in Spark SQL to write a DataFrame to a table, Spark stores the table's data in this warehouse directory. It functions similarly to a traditional database's data storage, but it's file-based and used directly by Spark.  \n",
        "\n",
        "In this section of the lab, we will explore how to utilize PySpark's toTable method to persist streaming data into a table stored in Parquet format.  "
      ],
      "metadata": {
        "id": "5YROyE8M9HPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "query_name='parquet_table'\n",
        "query_parquet_2 = (\n",
        "    df.writeStream\n",
        "    .format(\"parquet\")\n",
        "    .option(\"checkpointLocation\",\"checkpoint3\")\n",
        "    .option(\"path\", query_name)\n",
        "    .queryName(query_name)\n",
        "    .trigger(processingTime='30 seconds')\n",
        "    .toTable(query_name) # With this option, files are written inside spark-warehouse\n",
        ")"
      ],
      "metadata": {
        "id": "nYwcjU2m9CxT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Get the list of active streaming queries\n",
        "active_queries = spark.streams.active\n",
        "\n",
        "# Print details about each active query\n",
        "for query in active_queries:\n",
        "    # query.stop()\n",
        "    print(f\"Query Name: {query.name}\")\n",
        "    print(f\"Query ID: {query.id}\")\n",
        "    print(f\"Query Status: {query.status}\")\n",
        "    print(f\"Is Query Active: {query.isActive}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "m-SpKIuA9CsT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "spark.sql(f'SELECT * FROM {query_name}').toPandas()"
      ],
      "metadata": {
        "id": "xQwpns6b9Cld",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DuckDB is a modern database that natively reads parquet files"
      ],
      "metadata": {
        "id": "53roiGMpGIAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "warehouse='/content/spark-warehouse/parquet_table/*.parquet'"
      ],
      "metadata": {
        "id": "yqIpM91nGNFH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import duckdb\n",
        "\n",
        "duckdb.sql(f\"SELECT * FROM read_parquet('{warehouse}', hive_partitioning=1)  LIMIT 10;\")\n"
      ],
      "metadata": {
        "id": "HQSnljFsGL-0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Commands to inspect Kafka's status:"
      ],
      "metadata": {
        "id": "z3IREe9LkYVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "\n",
        "kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list"
      ],
      "metadata": {
        "id": "XI15qeDmuqvg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "\n",
        "kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list"
      ],
      "metadata": {
        "id": "MrWjPpmaAfLl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%shell\n",
        "\n",
        "source ./environment.sh\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups"
      ],
      "metadata": {
        "id": "R6AlCSh8AZc9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%shell\n",
        "consumer_group_name=\"Python_AVRO_Consumer\"\n",
        "\n",
        "source ./environment.sh\n",
        "\n",
        "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group $consumer_group_name --describe"
      ],
      "metadata": {
        "id": "8NGFKSHbkW4t",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!ps -ef |grep avro"
      ],
      "metadata": {
        "id": "x5tcGTIb70_P",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!ls *log"
      ],
      "metadata": {
        "id": "svd3Qf6X72HH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!tail -10 kafka_consumers.log"
      ],
      "metadata": {
        "id": "IxwVQuof74KS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!tail -10 avro_producer.log"
      ],
      "metadata": {
        "id": "PDI8faCpB-yk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Set to True and run cell when you want to stop your queries and Spark job.\n",
        "if False:\n",
        "  # Get the list of active streaming queries\n",
        "  active_queries = spark.streams.active\n",
        "\n",
        "# Print details about each active query\n",
        "  for query in active_queries:\n",
        "      query.stop()\n",
        "      print(f\"Query Name: {query.name}\")\n",
        "      print(f\"Query ID: {query.id}\")\n",
        "      print(f\"Query Status: {query.status}\")\n",
        "      print(f\"Is Query Active: {query.isActive}\")\n",
        "      print(\"-\" * 50)\n",
        "  spark.stop()\n",
        "  spark.sparkContext.stop()"
      ],
      "metadata": {
        "id": "x7HGImhjHpq9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}